server:
python -m vllm.entrypoints.openai.api_server  --model /data00/Mistral-7B-Instruct-v0.3 --tensor-parallel-size 1 --max-model-len 3000 --gpu-memory-utilization 0.9 --distributed-executor-backend mp

client: 
python benchmarks/benchmark_serving.py --host ip --backend vllm --model /data00/Mistral-7B-Instruct-v0.3 --dataset-name sharegpt --dataset-path /data00/ShareGPT_Vicuna_unfiltered/ShareGPT_V4.3_unfiltered_cleaned_split.json
